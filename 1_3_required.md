# これからの３Dと画像認識の連携で必要となる実装（私見）
- 2Dの物体検出をOpen3Dベースの深度情報と関連付けられること
- 2Dのインスタンスセグメンテーションの結果をOpen3Dベースの深度情報と関連付けられること
  - インスタンスセグメンテーションで絞り込まれた領域から、深度分布のパーセンタイル値が算出できること
- 物体検出の結果に対する追跡
  - ３Dとしての物体検出では、対象物の空間的位置が重なることが生じにくい。
  - 3Dでの物体の追跡は、2Dの場合よりも安定になりやすい。
- 人検出・人のポーズ推定に関わるライブラリが3Dカメラと連携がとれること
- 顔検出だけでなく、顔照合を3Dカメラで連携がとれること。
  - 3Dでの追跡ができることを利用して、顔照合の頻度は減らせること。
  - 顔照合は、利用可能なライブラリの情報を含める（商用ライブラリも含める）。
- IMUを使って、世界座標系に対する点群の位置を算出できること
- 過去フレームのデータも使って、環境の点群・着目している対象物の点群を生成できること
## 生成系AIの進展を反映させたい実装
- 見えていない側の領域を補完する点群（あるいはメッシュ）の生成

## 定型的な処理としてあってほしいもの
- 物体の大きさの計測
  - 例：段ボール箱の大きさの計測
  - 例：農産物の大きさによる分類
- 凸物体についての自動での画像分類
- 背景と凸物体との分離
- 固定の配置の対象物とそれ以外の分離　 

# マシンビジョン分野での３Dカメラと画像認識
- 制御された環境での画像認識技術は、マシンビションと呼ばれることが多い。
- マシンビジョンでありがちな条件
  - カメラの位置が固定である。
  - 対象物の背景は制御できる。
  - 照明条件も制御できる。
- 制御された環境での利点
  - 差分画像を利用できる。
  - 対象物の見える領域を絞りこむことができる。

# 現状の3D計測・画像認識をベースとした移動するロボットへの私見
- 画像認識技術を用いたロボットが、従来は制御された環境だったのが、制御されていない環境に変化してきている。
- このことは、ロボットに対して求められる設計思想にも、変化を生じている。
- 従来：
  - 制御された環境において、制御された対象物に対して、決まりきった動作を行うためのビジョン技術だった。
- 現在進行中の分野：
  - 制御されていない環境で、変動の大きな対象物に対して、対象物の状況に応じた動作をすることが求められている。

## 制御されていない環境では、リピータビリティは意味が少ない。
- 制御されていない環境では、まったく同じ状況になることが少ないので、同じ動作を精度よく繰り返すことが意味が少ない。
- ペンダントを使って教示できるような状況ではない。
- １回の計測を高精度で行えばあとは対象物へのハンドリング開始を待てばよいという枠組みは、変動する環境では成り立ちません。
- 絶えず、今の状況確認しながら行動を修正し続けることが必要になってくる。
- その結果、1mm程度の位置精度（あるいはそれよりも高精度）を求めることは意味を持たなくなっている。

## 移動するロボットを想定することで、設計思想は変わる。
- ロボットの手首付近にカメラを設置する例が多い。
- アームの先端に近いほど、モーメントが大きくなってしまう。
- モーメントを小さくするには、アームの先端に付けるカメラは軽量であることが求められる。
- 移動するロボットにおいて、ロボットのアームに剛性を高めることは得策じゃない。
- 柵の中でだったら、位置制御による動作が許されるが、柵の外では、ぶつからないこと、ぶつかっても衝撃が少ないことが求められる。
- そのため制御方式も制御のために必要になるセンサ類も変わってくる。

## 身体性のあり方と制御とセンシングは密接に関係している。
- 動作速度が速ければ、それに見合う分だけセンシングも応答時間が短いことが必要となる。
- 足場の悪いところを2足歩行させようとすると、それに応じてセンシングと制御とが対応できることが必要になる。
- どちらか一方だけの変更で対応できることはすくない。
- 画像認識は、センシングの一部にすぎない。
- IMUやタッチセンサとの連動の中で、画像認識（とプラスアルファ）の学習を習得させる。
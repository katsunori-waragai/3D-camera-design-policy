# 座標系の問題

## アプリケーションごとの座標系の違い
空間座標を取り扱う段階になると、アプリケーションごとに座標系の定義が異なるという問題に直面する。

https://pbs.twimg.com/media/GZAINdAbAAU09fW?format=jpg&name=small

![img.png](figure/coordinates.png)

### ZED SDK の場合の座標系の設定
[Selecting a Coordinate System](https://www.stereolabs.com/docs/positional-tracking/coordinate-frames)
デフォルトの座標系
ｘ：左から右
y：上から下
Z:カメラから前方へ

注：この向きがデフォルトになる理由
画像での座標の扱いは
画像上の横をｘ、画像上の縦方向をｙとしている。
その画像上のｘ，ｙとの３次元空間でのx,yの向きが同じになるものがデフォルトとして選ばれている。

InitParameters.coordinate_system の値を変更することで、
６通りの定義を切り替えることができる。


[3Dモデリングでハマるカメラ座標系の罠](https://qiita.com/astaka/items/d5048ed943c6a285ae62)

### 複数センサのキャリブレーション

https://github.com/PJLab-ADG/SensorsCalibration

センサーのキャリブレーションは、あらゆる自律システムとそれを構成するセンサーの基礎ブロックであり、センサーフュージョンを実装する前に正しく実行されなければならない。正確なキャリブレーションは、センサーフュージョンや、障害物検出、ローカライゼーション、マッピング、制御のためのアルゴリズムの実装など、さらなる処理ステップに不可欠です。
さらに、センサーフュージョンは、自律走行アプリケーションにおいて不可欠なタスクの一つであり、複数のセンサーから得られた情報を融合することで、センサーを個別に使用する場合よりも不確実性を低減する。
自律走行車のセンサキャリブレーションの問題を解決するために、我々はセンサキャリブレーションツールボックスを提供する。
キャリブレーションツールボックスは、IMU、LiDAR、カメラ、レーダーなどのセンサーのキャリブレーションに使用できます。

